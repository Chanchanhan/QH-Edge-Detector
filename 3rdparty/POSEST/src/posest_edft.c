/*
//////////////////////////////////////////////////////////////////////////////////////////////////////////
//
//  Non-linear calibrated camera pose estimation from contour matching and inner pixel intensity matching
//  Bin Wang (binwangsdu@gmail.com)
//
//////////////////////////////////////////////////////////////////////////////////////////////////////////
*/

#include <stdio.h>
#include <stdlib.h>
#include <malloc.h>
#include <string.h>
#include <math.h>
#include <float.h>

#include "../../POSEST/include/posest_edft.h"
#include "../../POSEST/include/sam.h"
#include "../../POSEST/include/compiler.h"
#include "../../POSEST/include/util.h"
#include "../../POSEST/include/poseproj.h"

#include "../../POSEST/include/levmar/levmar.h"
#include "../../POSEST/include/levmar/mestimators.h"
#include "../../POSEST/include/mlsl/mlsl.h"


/* minimal number of contour point and inner points */
#define NUM_PTS 6

#define USE_ROBUST_LM       1// enable robustified L-M?
#define USE_INPLACE_REFN    1// enable in-place parameterization for refinement


/* variables used by various estimation routines */
struct EDFTdata 
{
	double *K; // intrinsics
	float *distMap; // distance map
	double(*ctrPts3D)[3]; // contour points
	int nCtrPts; // the number of contour points

	int width, height; // the (width, height) of distMap
};

/* compute the rotation vector corresponding to a rotation matrix; see A8 in Horn's paper
* Similar to sam_rotmat2vec() with the addition of a return code.
*
* returns 0 if successful, 1 otherwise
*/
#define _CLAMP(a, b, x) ( ((x)<=(a))? (a) : (((x)<=(b))? (x) : (b)) )
static int rotmat2rodr(double R[9], double rv[3])
{
	register int i;
	int maxpos = -1; /* -Wall */
	double q[4], tmp[4], mag, s, th;

	/* convert to quaternion */
	/* find the maximum of the 4 quantities */
	tmp[0] = 1.0 + R[0] + R[4] + R[8];
	tmp[1] = 1.0 + R[0] - R[4] - R[8];
	tmp[2] = 1.0 - R[0] + R[4] - R[8];
	tmp[3] = 1.0 - R[0] - R[4] + R[8];

	for (i = 0, mag = -1.0; i < 4; i++)
		if (tmp[i] > mag){
		mag = tmp[i];
		maxpos = i;
		}

	switch (maxpos){
	case 0:
		q[0] = sqrt(tmp[0])*0.5;
		q[1] = (R[7] - R[5]) / (4.0*q[0]);
		q[2] = (R[2] - R[6]) / (4.0*q[0]);
		q[3] = (R[3] - R[1]) / (4.0*q[0]);
		break;
	case 1:
		q[1] = sqrt(tmp[1])*0.5;
		q[0] = (R[7] - R[5]) / (4.0*q[1]);
		q[2] = (R[3] + R[1]) / (4.0*q[1]);
		q[3] = (R[2] + R[6]) / (4.0*q[1]);
		break;
	case 2:
		q[2] = sqrt(tmp[2])*0.5;
		q[0] = (R[2] - R[6]) / (4.0*q[2]);
		q[1] = (R[3] + R[1]) / (4.0*q[2]);
		q[3] = (R[7] + R[5]) / (4.0*q[2]);
		break;
	case 3:
		q[3] = sqrt(tmp[3])*0.5;
		q[0] = (R[3] - R[1]) / (4.0*q[3]);
		q[1] = (R[2] + R[6]) / (4.0*q[3]);
		q[2] = (R[7] + R[5]) / (4.0*q[3]);
		break;
	default: /* should not happen */
		fprintf(stderr, "Internal error in rotmat2rodr()\nR:\n");
		fprintf(stderr, "%g %g %g\n", R[0], R[1], R[2]);
		fprintf(stderr, "%g %g %g\n", R[3], R[4], R[5]);
		fprintf(stderr, "%g %g %g\n", R[6], R[7], R[8]);
		return 1;
		//exit(1);
	}

	/* enforce unit length */
	mag = q[0] * q[0] + q[1] * q[1] + q[2] * q[2] + q[3] * q[3];

	if (mag != 1.0){
		mag = 1.0 / sqrt(mag);
		q[0] *= mag; q[1] *= mag; q[2] *= mag; q[3] *= mag;
	}

	th = acos(_CLAMP(-1.0, 1.0, q[0]));
	s = sin(th);
	th = 2.0*th;
	if (fabs(s) > 1E-08){
		th /= s;
		rv[0] = q[1] * th;
		rv[1] = q[2] * th;
		rv[2] = q[3] * th;
	}
	else{ // s close to zero, axis direction unimportant
		rv[0] = th;
		rv[1] = rv[2] = 0.0;
	}

	return 0;
}
#undef _CLAMP


/* compute the rotation matrix corresponding to a rotation vector.
* Code generated by maple's codegen package and minimal editing (rodrigues.mpl)
*/
static void rvec2rotmat(double r[3], double R[9])
{
	double t1, t2, t3, t4, t5, t6, t7, t8, t9, t10, t14, t16, t17, t18, t20, t22, t24, t27, t31, t33;

	t1 = r[0] * r[0];
	t2 = r[1] * r[1];
	t3 = r[2] * r[2];
	t4 = t1 + t2 + t3;

	if (t4 <= 1E-14){ // zero, R=I
		R[0] = R[4] = R[8] = 1.0;
		R[1] = R[2] = R[3] = R[5] = R[6] = R[7] = 0.0;
		return;
	}

	t5 = sqrt(t4);
#ifdef _MSC_VER
	__asm {
		fld QWORD PTR[t5]
			fsincos
			fstp QWORD PTR[t6]; cosine
			fstp QWORD PTR[t14]; sine
	}
#else
	SINCOS(t5, &t14, &t6);
	//t6 = cos(t5);
	//t14 = sin(t5);
#endif
	t7 = 1.0 - t6;
	t8 = 1 / t4;
	t9 = t8*t3;
	t10 = t8*t2;
	t16 = t14 / t5;
	t17 = t16*r[2];
	t18 = t7*t8;
	t20 = t18*r[1] * r[0];
	t22 = t16*r[1];
	t24 = t18*r[2] * r[0];
	t27 = t8*t1;
	t31 = t16*r[0];
	t33 = t18*r[2] * r[1];
	R[0] = 1.0 + t7*(-t9 - t10);
	R[1] = -t17 + t20;
	R[2] = t22 + t24;
	R[3] = t17 + t20;
	R[4] = 1.0 + t7*(-t9 - t27);
	R[5] = -t31 + t33;
	R[6] = -t22 + t24;
	R[7] = t31 + t33;
	R[8] = 1.0 + t7*(-t10 - t27);
}

/* P = K [R t] */
void posest_edft_PfromKRt(double P[NUM_PPARAMS], double K[9], double rt[NUM_RTPARAMS])
{
	register int j;
	double R[9], *t = rt + 3;

	rvec2rotmat(rt, R);

	/* compute the j-th row of K*[R t] */
	for (j = 0; j < 3; ++j){
		P[j] = K[0] * R[j] + K[1] * R[3 + j] + K[2] * R[6 + j];
		P[3] = K[0] * t[0] + K[1] * t[1] + K[2] * t[2];

		/* K[3] assumed zero */
		P[4 + j] = K[4] * R[3 + j] + K[5] * R[6 + j];
		P[7] = K[4] * t[1] + K[5] * t[2];

		/* K[6], K[7] assumed zero */
		P[8 + j] = K[8] * R[6 + j];
		P[11] = K[8] * t[2];
	}
}


/* contour matching error and Jacobian */
static void ptsEDFTRT(double *rt, double *x, int m, int n, void *adata)
{
	struct EDFTdata *dat = (struct EDFTdata *)adata;
	int nCtrPts = dat->nCtrPts;
	double *K = dat->K, (*ctrPts3D)[3] = dat->ctrPts3D;
	float *distMap = dat->distMap;
	int width = dat->width, height = dat->height;
	register int i, j, k;

	//assert(m == 6 && n == nCtrPts);

	double P[NUM_PPARAMS], X, Y, Z, s, ppt[2];
	int u, v;
	/* P=K[R t] */
	posest_edft_PfromKRt(P, K, rt);
	for (i = 0; i<nCtrPts; ++i)
	{
		X = ctrPts3D[i][0]; Y = ctrPts3D[i][1]; Z = ctrPts3D[i][2];
		// parentheses below break dependency chains
		s = 1.0 / ((P[8] * X + P[9] * Y) + (P[10] * Z + P[11]));
		ppt[0] = ((P[0] * X + P[1] * Y) + (P[2] * Z + P[3]))*s;
		ppt[1] = ((P[4] * X + P[5] * Y) + (P[6] * Z + P[7]))*s;
		u = (int)(ppt[0]);
		v = (int)(ppt[1]);

		if (u >= 0 && u < width && v >= 0 && v < height) // projected point is in image
		{
			j = v*width + u; // the pixel index
			x[i] = distMap[j];
		}
		else
		{
			x[i] = 0;
		}
	}
}

static void ptsEDFTRTJac(double *rt, double *jac, int m, int n, void *adata)
{
	register int i, j;
	struct EDFTdata *dat = (struct EDFTdata *)adata;
	int nCtrPts = dat->nCtrPts;
	double *K = dat->K, (*ctrPts3D)[3] = dat->ctrPts3D;
	float *distMap = dat->distMap;
	int width = dat->width, height = dat->height;
	register double *jacrow;

	//assert(m == 6 && n == nCtrPts);

	//memset(jac, 0, m*n*sizeof(double));

#if 1 /* fast version based on computing and reusing P with the chain rule */
	{
		double P[NUM_PPARAMS], X, Y, Z, s, ppt[2];
		int u, v, left, right, up, down;
		double gradm[2], gradP[2 * 12], gradrt[12 * 6], gradPXgradrt[2 * 6];

		posest_edft_PfromKRt(P, K, rt);
		calc_posePRTJac(K, rt, (double(*)[6])gradrt); // d P / d rt 12*6

		// for contour points
		for (i = 0, jacrow = jac; i < nCtrPts; ++i, jacrow += 1 * 6)
		{
			X = ctrPts3D[i][0]; Y = ctrPts3D[i][1]; Z = ctrPts3D[i][2];
			s = 1.0 / ((P[8] * X + P[9] * Y) + (P[10] * Z + P[11]));
			ppt[0] = ((P[0] * X + P[1] * Y) + (P[2] * Z + P[3]))*s;
			ppt[1] = ((P[4] * X + P[5] * Y) + (P[6] * Z + P[7]))*s;
			u = (int)(ppt[0]);
			v = (int)(ppt[1]);

			// dI / dm 1*2
			if (u >= 1 && u < width - 1 && v >= 1 && v < height - 1) // projected point is in image
			{
				left = v*width + u - 1; // the left pixel index
				right = v*width + u + 1; // the right pixel index
				up = (v - 1)*width + u; // the up pixel index
				down = (v + 1)*width + u; // the down pixel index
				gradm[0] = (distMap[right] - distMap[left]) / 2.0; // the finite difference along x direction
				gradm[1] = (distMap[down] - distMap[up]) / 2.0; // the finite difference along y direction
			}
			else
			{
				gradm[0] = 0; // the finite difference along x direction
				gradm[1] = 0; // the finite difference along y direction
			}

			calc_poseProjPJac(P, ctrPts3D[i], (double(*)[12])gradP); // d m / d P 2*12

			/*dI / drt = dI / dm * dm / drt
			*
			* dm / drt = dm / dP * dP / drt
			* unrolled multiplication jacrow=gradP*gradrt; parentheses are used to break dependency chains
			*
			* gradP is sparse: [x x x x 0 0 0 0 x x x x; 0 0 0 0 x x x x x x x x], hence we can exploit this
			* to avoid a few multiplications
			*/
			//for(j=0; j<6; ++j)
			for (j = 6; j-- > 0;)
			{
				// dm / drt = dm / dP * dP / drt
				gradPXgradrt[0 * 6 + j] =
					((gradP[0 * 12 + 0] * gradrt[0 * 6 + j] + gradP[0 * 12 + 1] * gradrt[1 * 6 + j]) + (gradP[0 * 12 + 2] * gradrt[2 * 6 + j] + gradP[0 * 12 + 3] * gradrt[3 * 6 + j])) +
					//((gradP[0*12+4]*gradrt[4*6+j] + gradP[0*12+5]*gradrt[5*6+j]) + (gradP[0*12+6] *gradrt[6*6+j] +  gradP[0*12+7] *gradrt[7*6+j])) +
					((gradP[0 * 12 + 8] * gradrt[8 * 6 + j] + gradP[0 * 12 + 9] * gradrt[9 * 6 + j]) + (gradP[0 * 12 + 10] * gradrt[10 * 6 + j] + gradP[0 * 12 + 11] * gradrt[11 * 6 + j]));

				gradPXgradrt[1 * 6 + j] =
					//((gradP[1*12+0]*gradrt[0*6+j] + gradP[1*12+1]*gradrt[1*6+j]) + (gradP[1*12+2] *gradrt[2*6+j] +  gradP[1*12+3] *gradrt[3*6+j])) +
					((gradP[1 * 12 + 4] * gradrt[4 * 6 + j] + gradP[1 * 12 + 5] * gradrt[5 * 6 + j]) + (gradP[1 * 12 + 6] * gradrt[6 * 6 + j] + gradP[1 * 12 + 7] * gradrt[7 * 6 + j])) +
					((gradP[1 * 12 + 8] * gradrt[8 * 6 + j] + gradP[1 * 12 + 9] * gradrt[9 * 6 + j]) + (gradP[1 * 12 + 10] * gradrt[10 * 6 + j] + gradP[1 * 12 + 11] * gradrt[11 * 6 + j]));

				// dI / drt = dI / dm * dm / drt
				jacrow[j] = gradm[0] * gradPXgradrt[0 * 6 + j] + gradm[1] * gradPXgradrt[1 * 6 + j];
			}

			//printf("ctr jac %g %g %g %g %g %g\n", jacrow[0], jacrow[1], jacrow[2], jacrow[3], jacrow[4], jacrow[5]);
		}
	}
#endif
}

/* nonlinear refinement of camera pose; based on minimizing reprojection error
*
* doMLSL is 1 if the MLSL scheme schould be emplooyed, 0 otherwise
* inpl is 1 if function is called by refinePoseRT_inplace(), 0 otherwise
*/
static int refinePoseRT(double *p, struct EDFTdata *data, int doMLSL, int inpl, int verbose, double *final_e)
{
	register int i, j;
	double opts[LM_OPTS_SZ], info[LM_INFO_SZ], *x;
	int m, n; // # unknowns & # constraints
	int nCtrPts = data->nCtrPts;
	float *distMap = data->distMap;
	double(*ctrPts3D)[3] = data->ctrPts3D;

	void(*err)(double *p, double *hx, int m, int n, void *adata);
	void(*jacerr)(double *p, double *j, int m, int n, void *adata);
	int ret;

	opts[0] = LM_INIT_MU; opts[1] = 1E-12; opts[2] = 1E-12; opts[3] = 1E-15;
	opts[4] = LM_DIFF_DELTA; // relevant only if the finite difference Jacobian version is used 

	m = NUM_RTPARAMS; n = nCtrPts; // one measurement per point
	if ((x = (double *)malloc(n*sizeof(double))) == NULL)
	{
		fprintf(stderr, "Memory allocation request failed in refinePoseRT()\n");
		exit(1);
	}
	// here we set all measures to zero, the err will be computed in the err_function
#if 1
	memset(x, 0, n*sizeof(double)); 
#else
	for (i = 0; i < n; ++i)
		x[i] = 0.0;
#endif

	err = ptsEDFTRT;
	jacerr = ptsEDFTRTJac;

	if (doMLSL)
	{
		double lb[NUM_RTPARAMS], ub[NUM_RTPARAMS], minL2sq;
		double scl[NUM_RTPARAMS];

		/* setup bounds & expected magnitudes; translation in cm -- CHECKME */
		if (!inpl)
		{
			if (verbose) printf("Previous frame pose: %g %g %g %g %g %g\n", p[0], p[1], p[2], p[3], p[4], p[5]);
			scl[0] = 1.0;  scl[1] = 2.0;  scl[2] = 1.0;
			scl[3] = 30.; scl[4] = 30.; scl[5] = 150.;

			lb[0] = -1.5 + p[0];    ub[0] = 1.5 + p[0];
			lb[1] = -1.5 + p[1];    ub[1] = 1.5 + p[1];
			lb[2] = -1.5 + p[2];    ub[2] = 1.5 + p[2];
			lb[3] = -30. + p[3];   ub[3] = 30. + p[3];
			lb[4] = -30. + p[4];   ub[4] = 30. + p[4];
			lb[5] = -70. + p[5];   ub[5] = 70. + p[5];
		}
		else
		{ // in-place
			if (verbose) printf("Previous frame pose (in-place): %g %g %g %g %g %g\n", p[0], p[1], p[2], p[3], p[4], p[5]);
			scl[0] = 1.0;        scl[1] = 1.0;        scl[2] = 1.0;
			scl[3] = fabs(p[3]); scl[4] = fabs(p[4]); scl[5] = fabs(p[5]);

			lb[0] = -1.5 + p[0];    ub[0] = 1.5 + p[0];
			lb[1] = -1.5 + p[1];    ub[1] = 1.5 + p[1];
			lb[2] = -1.5 + p[2];    ub[2] = 1.5 + p[2];
			lb[3] = -100. + p[3];  ub[3] = 100. + p[3];
			lb[4] = -100. + p[4];  ub[4] = 100. + p[4];
			lb[5] = -150. + p[5];  ub[5] = 150. + p[5];
		}

# if 0
		printf("L bounds: %g %g %g %g %g %g\n", lb[0], lb[1], lb[2], lb[3], lb[4], lb[5]);
		printf("U bounds: %g %g %g %g %g %g\n", ub[0], ub[1], ub[2], ub[3], ub[4], ub[5]);
#endif

		/* refine PnP pose and use it to initiate MLSL */
//  		ret = dlevmar_der(err, jacerr, p, x, m, n, 1000, opts, info, NULL, NULL, (void *)data); // with analytic Jacobian

 		mlsl_dlevmar_der(err, jacerr, p, x, m, n, lb, ub, scl, 500, opts, info, NULL, NULL, (void *)data, &minL2sq, 5, 1, verbose);
		if (verbose) printf("MLSL pose: %g %g %g %g %g %g, error %g\n", p[0], p[1], p[2], p[3], p[4], p[5], minL2sq / n);
	}

#if USE_ROBUST_LM==0
	ret = dlevmar_der(err, jacerr, p, x, m, n, 1000, opts, info, NULL, NULL, (void *)data); // with analytic Jacobian
	//ret=dlevmar_dif(err, p, x, m, n, 1000, opts, info, NULL, NULL, (void *)data); // no Jacobian
#else
	double rp[2];

#ifdef USED_IN_ORIGINAL_CODE
	/* use convex cost function first, then non-convex */
	rp[0] = ME_FAIR; rp[1] = 1.3998; // Fair 0.6
	ret = dlevmar_rob_der(err, jacerr, p, x, m, n, rp, 1000, opts, info, NULL, NULL, (void *)data);
	//rp[0] = ME_TUKEY; rp[1] = 4.6851;//; // Tukey 0.20
	rp[0] = ME_GEMANMCCLURE; rp[1] = 2.3849; // Geman-McClure 0.25
// 	ret = dlevmar_rob_der(err, jacerr, p, x, m, n, rp, 100, opts, info, NULL, NULL, (void *)data);
#else
// 	ret = dlevmar_der(err, jacerr, p, x, m, n, 1000, opts, info, NULL, NULL, (void *)data);

	//rp[0] = ME_TUKEY; rp[1] = 20.0;
	//ret = dlevmar_rob_der(err, jacerr, p, x, m, n, rp, 1000, opts, info, NULL, NULL, (void *)data);
#endif

#endif /* USE_ROBUST_LM */

	if (verbose)
	{
		fprintf(stdout, "\nRefinement using %d measurements, %d variables\n", n, m);
		fprintf(stdout, "LM returned %d in %g iter, reason %g, error %g [initial %g], %d/%d func/fjac evals\n",
			ret, info[5], info[6], info[1] / n, info[0] / n, (int)info[7], (int)info[8]);
#if 0
		fprintf(stdout, "\nSolution: ");
		for (i = 0; i<m; ++i)
			fprintf(stdout, "%.7g ", p[i]);
		fprintf(stdout, "\n");
#endif
	}

	free(x);

	*final_e = info[1];

	return ret;
}

/* nonlinear refinement of camera pose using an in-place parameterization;
* based on minimizing reprojection error
*
* Posest computes the pose Rp,t transforming points from bundler to camera frame:
* Mc=Rp*Mb + tp (1)
* The in-place refinement computes a correction dR,dt so that
* Mc'=dR*(Mc-C) + C + dt (2), with C being the center of rotation (the point's
* centroid). Therefore, substituting (1) into (2) gives
* Mc'=dR*Rp*Mb + dR*(tp-C) + C + dt,
* which gives the overall pose in posest's convention (bundler to camera) as
* R=dR*Rp, t=dR*(tp-C) + C + dt
*
* Note also that (2) implies that dR,C+dt can be estimated with refinePoseRT()
* applied to the transformed input points (Mc-C)
*/
static int refinePoseRT_inplace(double *p, struct EDFTdata *data, int doMLSL, int verbose, double *final_e)
{
	register int i, j;
	int nCtrPts = data->nCtrPts;
	double(*ctrPts3D)[3] = data->ctrPts3D;
	double X, Y, Z, dp[NUM_RTPARAMS];
	double cent[3], // C
		Rp[9], tp[3], // pose estimate (from previous frame)
		tp_cent[3], // tp-C
		dR[9], totR[9];
	int ret;

	if (verbose) printf("Initial pose (from previous frame): %g %g %g %g %g %g\n", p[0], p[1], p[2], p[3], p[4], p[5]);

	/* compute points centroid */
	cent[0] = cent[1] = cent[2] = 0.0;
	for (i = 0; i<nCtrPts; ++i)
	{
		cent[0] += ctrPts3D[i][0];
		cent[1] += ctrPts3D[i][1];
		cent[2] += ctrPts3D[i][2];
	}

	cent[0] /= (double)nCtrPts; cent[1] /= (double)nCtrPts; cent[2] /= (double)nCtrPts;

	/* transform 3D points with supplied pose & translate centroid to origin: Rp*M+tp-cent */
	rvec2rotmat(p, Rp);
	tp[0] = p[3]; tp[1] = p[4]; tp[2] = p[5];
	tp_cent[0] = tp[0] - cent[0]; tp_cent[1] = tp[1] - cent[1]; tp_cent[2] = tp[2] - cent[2];
	for (i = 0; i<nCtrPts; ++i)
	{
		X = ctrPts3D[i][0]; Y = ctrPts3D[i][1]; Z = ctrPts3D[i][2];
		ctrPts3D[i][0] = Rp[0] * X + Rp[1] * Y + Rp[2] * Z + tp_cent[0];
		ctrPts3D[i][1] = Rp[3] * X + Rp[4] * Y + Rp[5] * Z + tp_cent[1];
		ctrPts3D[i][2] = Rp[6] * X + Rp[7] * Y + Rp[8] * Z + tp_cent[2];
	}

	/* estimate in-place pose refinement */
	dp[0] = 1E-04; dp[1] = dp[2] = 0.0; // dR=I, avoid singular case with r=[0 0 0]
	dp[3] = cent[0]; dp[4] = cent[1]; dp[5] = cent[2]; // we are actually estimating C+dt, initial dt=[0 0 0]

	ret = refinePoseRT(dp, data, doMLSL, 1, verbose, final_e);

	/* undo changes to 3D points: Rp'*(M-(tp-cent)) */
	for (i = 0; i<nCtrPts; ++i)
	{
		X = ctrPts3D[i][0] - (tp_cent[0]); Y = ctrPts3D[i][1] - (tp_cent[1]); Z = ctrPts3D[i][2] - (tp_cent[2]);
		ctrPts3D[i][0] = Rp[0] * X + Rp[3] * Y + Rp[6] * Z;
		ctrPts3D[i][1] = Rp[1] * X + Rp[4] * Y + Rp[7] * Z;
		ctrPts3D[i][2] = Rp[2] * X + Rp[5] * Y + Rp[8] * Z;
	}

	if (ret == LM_ERROR) goto bailout;

	/* incorporate estimated in-place pose to p */
	rvec2rotmat(dp, dR);
	/* totR=dR*Rp */
	for (i = 0; i<3; ++i)
		for (j = 0; j<3; ++j)
			totR[i * 3 + j] = dR[i * 3] * Rp[j] + dR[i * 3 + 1] * Rp[3 + j] + dR[i * 3 + 2] * Rp[2 * 3 + j];
	rotmat2rodr(totR, p); // sets p[0:2]

	/* dR*(tp-cent) + C+dt */
	p[3] = dR[0] * tp_cent[0] + dR[1] * tp_cent[1] + dR[2] * tp_cent[2] + dp[3];
	p[4] = dR[3] * tp_cent[0] + dR[4] * tp_cent[1] + dR[5] * tp_cent[2] + dp[4];
	p[5] = dR[6] * tp_cent[0] + dR[7] * tp_cent[1] + dR[8] * tp_cent[2] + dp[5];

bailout:
	return ret;
}

static int posestRT_edft(float *distMap, double(*ctrPts3D)[3], int nCtrPts,
	int width, int height, double K[9], double rt[NUM_RTPARAMS], int NLrefine, int verbose, double *final_e)
{
	register int i, j;
	int ret;
	struct EDFTdata dat;

	if (nCtrPts < NUM_PTS) return POSEST_ERR;  // too few points

	dat.K = K;
	dat.distMap = distMap;
	dat.ctrPts3D = ctrPts3D;
	dat.nCtrPts = nCtrPts;
	dat.width = width;
	dat.height = height;

	/* TODO: some methods to get a good initial estimate,
	**       here we just use the pose from the previous frame
	*/
	// TODO

	/* the initial estimate has now been computed. Time for the non-linear refinement */
	int nPtrs = nCtrPts;
	if (nPtrs >= NUM_RTPARAMS)
	{
		int withMLSL = (NLrefine == POSEST_EDFT_ERR_NLN_MLSL);

#  if USE_INPLACE_REFN==0
		j = refinePoseRT(rt, &dat, withMLSL, 0, verbose);
#  else
		j = refinePoseRT_inplace(rt, &dat, withMLSL, verbose, final_e);
#  endif

		ret = (j != LM_ERROR) ? POSEST_OK : POSEST_ERR;
		sam_rvecnorm(rt); // map rotation angle to [-pi, pi]
	}
	
	return ret;
}

int posest_edft(float *distMap, double(*ctrPts3D)[3], int nCtrPts,
	int width, int height, double K[9], double *pp, int npp, int NLrefine, int verbose, double *final_e)
{
	switch (npp)
	{
	case NUM_RTPARAMS:
		return posestRT_edft(distMap, ctrPts3D, nCtrPts,
			width, height, K, pp, NLrefine, verbose, final_e);
		break;

	default:
		fprintf(stderr, "unknown pose estimation case '%d' specified to posest_edft()\n", npp);
		exit(1);
	}


	return POSEST_ERR; // should not reach this point
}